{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6817f0c6",
   "metadata": {},
   "source": [
    "# Stage 5.2 – Key Moment Recall Pilot\n",
    "This notebook prepares the Method 2 scaffolding for the key-moment recall workflow (Stage 5.2). It mirrors the Stage 5.1 logic while re-pointing long-form respondents to the short-form key-moment event lists."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e009a2",
   "metadata": {},
   "source": [
    "## Workflow Overview\n",
    "1. Load Stage 5.1 assets (model events plus recall responses).\n",
    "2. Derive an Abbott Elementary pilot sample (3 long-form, 3 short-form).\n",
    "3. Generate the revised key-moment prompts for manual review (Step 3.2).\n",
    "4. Execute LLM scoring only after approval (Steps 3.3-3.6)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da78e035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: C:\\Users\\ashra\\Documents\\NeuralSense\\NeuralData\\clients\\544_WBD_CXCU\n",
      "Recall source path: results\\uv_open_ended_long_recall.csv\n",
      "Pilot output path: recall_openended\\key moment\\pilot_outputs\\recall_coded_responses_key_moment_pilot.csv\n",
      "OpenAI client available: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "import textwrap\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    from openai import OpenAI\n",
    "except ImportError:\n",
    "    OpenAI = None\n",
    "\n",
    "\n",
    "def find_project_root() -> Path:\n",
    "    candidates = [Path.cwd().resolve(), *Path.cwd().resolve().parents]\n",
    "    for candidate in candidates:\n",
    "        if (candidate / \"analysis\" / \"assemble_uv.ipynb\").exists():\n",
    "            return candidate\n",
    "    raise FileNotFoundError(\"Unable to locate project root (missing analysis/assemble_uv.ipynb).\")\n",
    "\n",
    "\n",
    "PROJECT_ROOT = find_project_root()\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "RESULTS_DIR = PROJECT_ROOT / \"results\"\n",
    "KEY_MOMENT_DIR = PROJECT_ROOT / \"recall_openended\" / \"key moment\"\n",
    "PILOT_OUTPUT_DIR = KEY_MOMENT_DIR / \"pilot_outputs\"\n",
    "PILOT_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MODEL_EVENTS_PATH = DATA_DIR / \"model_answers_events.md\"\n",
    "RECALL_SOURCE_PATH = RESULTS_DIR / \"uv_open_ended_long_recall.csv\"\n",
    "PILOT_OUTPUT_PATH = PILOT_OUTPUT_DIR / \"recall_coded_responses_key_moment_pilot.csv\"\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai_client = OpenAI(api_key=OPENAI_API_KEY) if (OpenAI and OPENAI_API_KEY) else None\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Recall source path: {RECALL_SOURCE_PATH.relative_to(PROJECT_ROOT)}\")\n",
    "print(f\"Pilot output path: {PILOT_OUTPUT_PATH.relative_to(PROJECT_ROOT)}\")\n",
    "print(f\"OpenAI client available: {openai_client is not None}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d20c180f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_title(title: str) -> str:\n",
    "    if not isinstance(title, str):\n",
    "        return \"\"\n",
    "    cleaned = re.sub(r\"\\s+\", \" \", title.strip()).lower()\n",
    "    cleaned = cleaned.replace(\"–\", \"-\").replace(\"—\", \"-\")\n",
    "    cleaned = cleaned.replace(\":\", \"\")\n",
    "    return cleaned\n",
    "\n",
    "\n",
    "def normalise_form(form: str) -> str:\n",
    "    if not isinstance(form, str):\n",
    "        return \"\"\n",
    "    cleaned = form.strip().lower().replace(\"–\", \"-\").replace(\"—\", \"-\")\n",
    "    cleaned = re.sub(r\"\\s+\", \" \", cleaned)\n",
    "    cleaned = cleaned.replace(\" form\", \"\")\n",
    "    alias_map = {\n",
    "        \"long\": \"long\",\n",
    "        \"long-form\": \"long\",\n",
    "        \"longform\": \"long\",\n",
    "        \"lf\": \"long\",\n",
    "        \"short\": \"short\",\n",
    "        \"short-form\": \"short\",\n",
    "        \"shortform\": \"short\",\n",
    "        \"sf\": \"short\",\n",
    "    }\n",
    "    return alias_map.get(cleaned, cleaned)\n",
    "\n",
    "\n",
    "def parse_model_events(path: Path) -> Dict[Tuple[str, str], List[str]]:\n",
    "    text = path.read_text(encoding=\"utf-8\")\n",
    "    # Match headers like \"## Abbot Elementary – Long Form\" or \"## Mad Max - Short Form\"\n",
    "    header_pattern = re.compile(r\"^##\\s*(.+?)\\s*[-–—]\\s*(.+?)\\s*$\", re.MULTILINE)\n",
    "    matches = list(header_pattern.finditer(text))\n",
    "    sections: Dict[Tuple[str, str], List[str]] = {}\n",
    "    if not matches:\n",
    "        raise ValueError(\"No section headers found in model_answers_events.md\")\n",
    "    for idx, match in enumerate(matches):\n",
    "        title_raw, form_raw = match.group(1).strip(), match.group(2).strip()\n",
    "        start = match.end()\n",
    "        end = matches[idx + 1].start() if idx + 1 < len(matches) else len(text)\n",
    "        section_text = text[start:end]\n",
    "        events = [\n",
    "            evt.strip()\n",
    "            for evt in re.findall(r\"^\\s*\\d+\\.\\s+(.*)$\", section_text, re.MULTILINE)\n",
    "            if evt.strip()\n",
    "        ]\n",
    "        key = (normalise_title(title_raw), normalise_form(form_raw))\n",
    "        sections[key] = events\n",
    "    return sections\n",
    "\n",
    "\n",
    "def load_recall_responses(path: Path) -> pd.DataFrame:\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "    except UnicodeDecodeError:\n",
    "        with path.open(\"r\", encoding=\"cp1252\", errors=\"ignore\") as fh:\n",
    "            df = pd.read_csv(fh)\n",
    "    df.columns = [col.strip().lower() for col in df.columns]\n",
    "    column_aliases = {\n",
    "        \"format\": \"form\",\n",
    "        \"media_format\": \"form\",\n",
    "        \"media_form\": \"form\",\n",
    "        \"content_form\": \"form\",\n",
    "    }\n",
    "    for candidate, target in column_aliases.items():\n",
    "        if candidate in df.columns and target not in df.columns:\n",
    "            df = df.rename(columns={candidate: target})\n",
    "    if \"id\" not in df.columns:\n",
    "        df.insert(0, \"id\", range(len(df)))\n",
    "    required = {\"id\", \"title\", \"form\", \"respondent\", \"response\"}\n",
    "    missing = required - set(df.columns)\n",
    "    if missing:\n",
    "        raise KeyError(f\"Recall dataset missing required columns: {sorted(missing)}\")\n",
    "    df[\"title\"] = df[\"title\"].astype(str).str.strip()\n",
    "    df[\"form\"] = df[\"form\"].astype(str).str.strip()\n",
    "    df[\"respondent\"] = df[\"respondent\"].astype(str).str.strip()\n",
    "    df[\"response\"] = df[\"response\"].fillna(\"\").astype(str)\n",
    "    if \"question_code\" in df.columns:\n",
    "        df[\"question_code\"] = df[\"question_code\"].astype(str).str.strip()\n",
    "    if \"questionnaire\" in df.columns:\n",
    "        df[\"questionnaire\"] = df[\"questionnaire\"].astype(str).str.strip()\n",
    "    df[\"title_key\"] = df[\"title\"].apply(normalise_title)\n",
    "    df[\"form_key\"] = df[\"form\"].apply(normalise_form)\n",
    "    return df\n",
    "\n",
    "\n",
    "ABBOTT_TITLE_KEY = normalise_title(\"Abbot Elementary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b22c0769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model events for 6 title/form combinations.\n",
      "Total recall responses: 162\n",
      "Forms present: ['long', 'short']\n",
      "Abbott Elementary responses: 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>respondent</th>\n",
       "      <th>group</th>\n",
       "      <th>questionnaire</th>\n",
       "      <th>question_code</th>\n",
       "      <th>question</th>\n",
       "      <th>form</th>\n",
       "      <th>title</th>\n",
       "      <th>response</th>\n",
       "      <th>title_key</th>\n",
       "      <th>form_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>116</td>\n",
       "      <td>A</td>\n",
       "      <td>Post</td>\n",
       "      <td>Q13</td>\n",
       "      <td>Recall</td>\n",
       "      <td>Long</td>\n",
       "      <td>Abbot Elementary</td>\n",
       "      <td>The black male actor lied about liking pizza and said he would only eat a certain type which he thought didn’t exist. He described it as wet. The white male actor drove to the city where the pizza...</td>\n",
       "      <td>abbot elementary</td>\n",
       "      <td>long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>F</td>\n",
       "      <td>Post</td>\n",
       "      <td>Q13</td>\n",
       "      <td>Recall</td>\n",
       "      <td>Long</td>\n",
       "      <td>Abbot Elementary</td>\n",
       "      <td>The guy grabbing the pizza in reality doesn’t like pizza but he is ashamed to admit at first because he doesn’t want to be judged. So he made up a fake pizza place from Baltimore that is extra sog...</td>\n",
       "      <td>abbot elementary</td>\n",
       "      <td>long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>109</td>\n",
       "      <td>F</td>\n",
       "      <td>Post</td>\n",
       "      <td>Q13</td>\n",
       "      <td>Recall</td>\n",
       "      <td>Long</td>\n",
       "      <td>Abbot Elementary</td>\n",
       "      <td>Greg, Jacob and staff were having lunch in the break room and the group started talking about pizza and decided that they should have a pizza contest where everyone brings their favorite pizza for...</td>\n",
       "      <td>abbot elementary</td>\n",
       "      <td>long</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id respondent group questionnaire question_code question  form  \\\n",
       "0   0        116     A          Post           Q13   Recall  Long   \n",
       "1   1        107     F          Post           Q13   Recall  Long   \n",
       "2   2        109     F          Post           Q13   Recall  Long   \n",
       "\n",
       "              title  \\\n",
       "0  Abbot Elementary   \n",
       "1  Abbot Elementary   \n",
       "2  Abbot Elementary   \n",
       "\n",
       "                                                                                                                                                                                                  response  \\\n",
       "0  The black male actor lied about liking pizza and said he would only eat a certain type which he thought didn’t exist. He described it as wet. The white male actor drove to the city where the pizza...   \n",
       "1  The guy grabbing the pizza in reality doesn’t like pizza but he is ashamed to admit at first because he doesn’t want to be judged. So he made up a fake pizza place from Baltimore that is extra sog...   \n",
       "2  Greg, Jacob and staff were having lunch in the break room and the group started talking about pizza and decided that they should have a pizza contest where everyone brings their favorite pizza for...   \n",
       "\n",
       "          title_key form_key  \n",
       "0  abbot elementary     long  \n",
       "1  abbot elementary     long  \n",
       "2  abbot elementary     long  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_events_lookup = parse_model_events(MODEL_EVENTS_PATH)\n",
    "recall_df = load_recall_responses(RECALL_SOURCE_PATH)\n",
    "\n",
    "# Normalize Abbott/Abbot spelling variations to match model events\n",
    "recall_df['title'] = recall_df['title'].replace({\n",
    "    'Abbot Elementary': 'Abbot Elementary',\n",
    "    'Abbott Elementary': 'Abbot Elementary'\n",
    "})\n",
    "recall_df['title_key'] = recall_df['title'].apply(normalise_title)\n",
    "\n",
    "print(f\"Loaded model events for {len(model_events_lookup)} title/form combinations.\")\n",
    "print(f\"Total recall responses: {len(recall_df)}\")\n",
    "print(f\"Forms present: {sorted(recall_df['form_key'].unique())}\")\n",
    "abbott_mask = recall_df['title_key'] == ABBOTT_TITLE_KEY\n",
    "print(f\"Abbott Elementary responses: {int(abbott_mask.sum())}\")\n",
    "recall_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01f93d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pilot_sample(responses: pd.DataFrame, title_key: str, *, n_long: int = 3, n_short: int = 3, seed: int = 20251111) -> pd.DataFrame:\n",
    "    target = responses.loc[responses[\"title_key\"] == title_key].copy()\n",
    "    if target.empty:\n",
    "        raise ValueError(f\"No responses found for title key '{title_key}'.\")\n",
    "    long_pool = target[target[\"form_key\"] == \"long\"]\n",
    "    short_pool = target[target[\"form_key\"] == \"short\"]\n",
    "    if long_pool.empty:\n",
    "        raise ValueError(\"No long-form respondents available for the pilot selection.\")\n",
    "    if short_pool.empty:\n",
    "        raise ValueError(\"No short-form respondents available for the pilot selection.\")\n",
    "    long_sample = long_pool.sample(n=min(n_long, len(long_pool)), random_state=seed, replace=False)\n",
    "    short_sample = short_pool.sample(n=min(n_short, len(short_pool)), random_state=seed + 1, replace=False)\n",
    "    pilot = pd.concat([long_sample, short_sample], ignore_index=True)\n",
    "    pilot = pilot.sort_values([\"form_key\", \"respondent\", \"id\"]).reset_index(drop=True)\n",
    "    pilot[\"pilot_order\"] = range(1, len(pilot) + 1)\n",
    "    return pilot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "188ac731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pilot sample size: 6\n",
      "Pilot composition (by form): {'long': 3, 'short': 3}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pilot_order</th>\n",
       "      <th>id</th>\n",
       "      <th>respondent</th>\n",
       "      <th>form</th>\n",
       "      <th>title</th>\n",
       "      <th>question_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>41</td>\n",
       "      <td>Long</td>\n",
       "      <td>Abbot Elementary</td>\n",
       "      <td>Q13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>62</td>\n",
       "      <td>Long</td>\n",
       "      <td>Abbot Elementary</td>\n",
       "      <td>Q18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>85</td>\n",
       "      <td>Long</td>\n",
       "      <td>Abbot Elementary</td>\n",
       "      <td>Q13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "      <td>108</td>\n",
       "      <td>Short</td>\n",
       "      <td>Abbot Elementary</td>\n",
       "      <td>Q13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>48</td>\n",
       "      <td>40</td>\n",
       "      <td>Short</td>\n",
       "      <td>Abbot Elementary</td>\n",
       "      <td>Q13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>69</td>\n",
       "      <td>Short</td>\n",
       "      <td>Abbot Elementary</td>\n",
       "      <td>Q13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pilot_order  id respondent   form             title question_code\n",
       "0            1   6         41   Long  Abbot Elementary           Q13\n",
       "1            2  90         62   Long  Abbot Elementary           Q18\n",
       "2            3  12         85   Long  Abbot Elementary           Q13\n",
       "3            4  45        108  Short  Abbot Elementary           Q13\n",
       "4            5  48         40  Short  Abbot Elementary           Q13\n",
       "5            6  50         69  Short  Abbot Elementary           Q13"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PILOT_RANDOM_SEED = 20251111\n",
    "pilot_df = build_pilot_sample(recall_df, ABBOTT_TITLE_KEY, seed=PILOT_RANDOM_SEED)\n",
    "\n",
    "summary = pilot_df.groupby(\"form_key\").size().to_dict()\n",
    "print(f\"Pilot sample size: {len(pilot_df)}\")\n",
    "print(f\"Pilot composition (by form): {summary}\")\n",
    "pilot_preview_cols = [\"pilot_order\", \"id\", \"respondent\", \"form\", \"title\", \"question_code\"]\n",
    "pilot_df.loc[:, pilot_preview_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e19ee46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pilot selection persisted to recall_openended\\key moment\\pilot_outputs\\keymoment_pilot_selection.csv\n"
     ]
    }
   ],
   "source": [
    "PILOT_SAMPLE_PATH = PILOT_OUTPUT_DIR / \"keymoment_pilot_selection.csv\"\n",
    "pilot_df.to_csv(PILOT_SAMPLE_PATH, index=False)\n",
    "print(f\"Pilot selection persisted to {PILOT_SAMPLE_PATH.relative_to(PROJECT_ROOT)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32e4867",
   "metadata": {},
   "source": [
    "## Prompt Scaffolding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0984e83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = textwrap.dedent(\n",
    "    \"\"\"\n",
    "    You are an expert qualitative coder focusing on key-moment recall for media research.\n",
    "    Scoring guidelines:\n",
    "    - The MODEL EVENTS describe the short-form key moment. Apply them even when the participant viewed the long-form cut.\n",
    "    - Compare the participant response to short-form key moment events and assess number of events recalled, accuracy, specificity, and ordering.\n",
    "    - Return strictly JSON with the following fields (integers for the scores):\n",
    "        - \"recall_score\": 0-100 (0 = no relevant recall, 100 = richly detailed and accurate).\n",
    "        - \"confidence_score\": 0-100 reflecting your certainty in the judgment.\n",
    "        - \"rationale\": 1-3 sentence explanation referencing the MODEL EVENTS.\n",
    "    - If the response states they do not remember, set recall_score to 0 and confidence_score to at least 90.\n",
    "    - Ignore long-form events or details that fall outside the MODEL EVENTS (they should not raise the score).\n",
    "    - Never invent events beyond the list, and do not include commentary outside the JSON payload.\n",
    "    \"\"\"\n",
    ").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "226a8f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_event_source(requested_form: str, applied_form: str) -> str:\n",
    "    if not applied_form:\n",
    "        return \"No model events located for this title.\"\n",
    "    if requested_form == applied_form:\n",
    "        return f\"{applied_form.title()} form events\"\n",
    "    if applied_form == \"short\":\n",
    "        return \"Short form key-moment events (applied to long-form response)\"\n",
    "    return f\"{applied_form.title()} form events (fallback; requested {requested_form})\"\n",
    "\n",
    "\n",
    "def get_key_moment_events(row: pd.Series, events_lookup: Dict[Tuple[str, str], List[str]]) -> Tuple[List[str], str]:\n",
    "    title_key = row[\"title_key\"]\n",
    "    requested_form = row[\"form_key\"]\n",
    "    if requested_form == \"long\":\n",
    "        preferred_key = (title_key, \"short\")\n",
    "        if preferred_key in events_lookup:\n",
    "            return events_lookup[preferred_key], \"short\"\n",
    "    primary_key = (title_key, requested_form)\n",
    "    if primary_key in events_lookup:\n",
    "        return events_lookup[primary_key], requested_form\n",
    "    fallback_short = (title_key, \"short\")\n",
    "    if fallback_short in events_lookup:\n",
    "        return events_lookup[fallback_short], \"short\"\n",
    "    fallback_long = (title_key, \"long\")\n",
    "    if fallback_long in events_lookup:\n",
    "        return events_lookup[fallback_long], \"long\"\n",
    "    return [], \"\"\n",
    "\n",
    "\n",
    "def build_prompt_block(row: pd.Series, events: List[str], event_source_label: str) -> str:\n",
    "    events_text = \"\\n\".join(f\"{idx + 1}. {event}\" for idx, event in enumerate(events)) if events else \"(No model events available.)\"\n",
    "    response_text = row.get(\"response\", \"\")\n",
    "    question_code = row.get(\"question_code\", \"\")\n",
    "    return textwrap.dedent(\n",
    "        f\"\"\"\n",
    "        Title: {row['title']}\n",
    "        Respondent form: {row['form']}\n",
    "        Event list source: {event_source_label}\n",
    "        Question code: {question_code}\n",
    "        Row ID: {row['id']}\n",
    "\n",
    "        MODEL EVENTS (chronological):\n",
    "        {events_text}\n",
    "\n",
    "        PARTICIPANT RESPONSE:\n",
    "        {response_text}\n",
    "\n",
    "        Evaluate this response and return a JSON object with keys id, recall_score, confidence_score, rationale.\n",
    "        \"\"\"\n",
    "    ).strip()\n",
    "\n",
    "\n",
    "def build_batch_prompt(batch_rows: pd.DataFrame, events_lookup: Dict[Tuple[str, str], List[str]]) -> Tuple[str, List[Tuple[str, str]], pd.DataFrame]:\n",
    "    blocks: List[str] = []\n",
    "    missing_keys: List[Tuple[str, str]] = []\n",
    "    metadata_records: List[Dict[str, object]] = []\n",
    "    for _, row in batch_rows.iterrows():\n",
    "        events, applied_form = get_key_moment_events(row, events_lookup)\n",
    "        requested_form = row[\"form_key\"]\n",
    "        if not events:\n",
    "            missing_keys.append((row[\"title_key\"], requested_form))\n",
    "        label = describe_event_source(requested_form, applied_form)\n",
    "        blocks.append(build_prompt_block(row, events, label))\n",
    "        metadata_records.append({\n",
    "            \"id\": int(row[\"id\"]),\n",
    "            \"respondent\": row.get(\"respondent\"),\n",
    "            \"title\": row.get(\"title\"),\n",
    "            \"form_requested\": row.get(\"form\"),\n",
    "            \"event_form_used\": applied_form or \"missing\",\n",
    "            \"event_count\": len(events),\n",
    "            \"event_label\": label,\n",
    "        })\n",
    "    prompt_text = \"\\n\\n\".join(blocks)\n",
    "    metadata_df = pd.DataFrame(metadata_records)\n",
    "    return prompt_text, missing_keys, metadata_df\n",
    "\n",
    "\n",
    "def call_llm_batch(prompt: str, client_obj=openai_client, model: str = \"gpt-4.1\", max_retries: int = 3, sleep_seconds: float = 2.0) -> str:\n",
    "    if client_obj is None:\n",
    "        raise RuntimeError(\"OpenAI client is not initialised. Set OPENAI_API_KEY before calling the model.\")\n",
    "    payload = [\n",
    "        {\"role\": \"system\", \"content\": [{\"type\": \"input_text\", \"text\": SYSTEM_PROMPT}]},\n",
    "        {\"role\": \"user\", \"content\": [{\"type\": \"input_text\", \"text\": prompt}]}\n",
    "    ]\n",
    "    last_error: Optional[Exception] = None\n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        try:\n",
    "            response = client_obj.responses.create(\n",
    "                model=model,\n",
    "                input=payload,\n",
    "                temperature=0.0,\n",
    "            )\n",
    "            return response.output_text\n",
    "        except Exception as exc:\n",
    "            last_error = exc\n",
    "            wait_for = sleep_seconds * (2 ** (attempt - 1))\n",
    "            print(f\"Attempt {attempt} failed: {exc}. Retrying in {wait_for:.1f}s\")\n",
    "            time.sleep(wait_for)\n",
    "    raise RuntimeError(\"Failed to retrieve LLM response\") from last_error\n",
    "\n",
    "\n",
    "def parse_llm_json(raw_output: str) -> List[Dict[str, object]]:\n",
    "    raw_output = raw_output.strip()\n",
    "    if raw_output.startswith(\"```\") and raw_output.endswith(\"```\"):\n",
    "        raw_output = re.sub(r\"^```[a-zA-Z]*\\n|```$\", \"\", raw_output).strip()\n",
    "    \n",
    "    # Try to parse as a single JSON array or object first\n",
    "    try:\n",
    "        parsed = json.loads(raw_output)\n",
    "        if isinstance(parsed, dict):\n",
    "            parsed = [parsed]\n",
    "    except json.JSONDecodeError:\n",
    "        # Try wrapping in array brackets in case it's multiple objects\n",
    "        try:\n",
    "            parsed = json.loads(f\"[{raw_output}]\")\n",
    "        except json.JSONDecodeError:\n",
    "            # If that fails, use regex to find all JSON objects in the text\n",
    "            parsed = []\n",
    "            # Pattern to match complete JSON objects including nested braces\n",
    "            json_pattern = r'\\{(?:[^{}]|(?:\\{(?:[^{}]|(?:\\{[^{}]*\\}))*\\}))*\\}'\n",
    "            matches = re.findall(json_pattern, raw_output, re.DOTALL)\n",
    "            for match in matches:\n",
    "                try:\n",
    "                    obj = json.loads(match)\n",
    "                    if isinstance(obj, dict):\n",
    "                        parsed.append(obj)\n",
    "                except json.JSONDecodeError:\n",
    "                    continue\n",
    "            \n",
    "            if not parsed:\n",
    "                raise ValueError(f\"Model returned non-JSON payload: {raw_output[:200]}\")\n",
    "    \n",
    "    if not isinstance(parsed, list):\n",
    "        raise ValueError(\"Expected list of JSON objects from model output\")\n",
    "    \n",
    "    cleaned: List[Dict[str, object]] = []\n",
    "    for entry in parsed:\n",
    "        if not isinstance(entry, dict):\n",
    "            continue\n",
    "        required = {\"id\", \"recall_score\", \"confidence_score\", \"rationale\"}\n",
    "        if not required.issubset(entry):\n",
    "            continue\n",
    "        cleaned.append({key: entry[key] for key in required})\n",
    "    return cleaned\n",
    "\n",
    "\n",
    "def enrich_dataframe_with_scores(df: pd.DataFrame, scored_rows: List[Dict[str, object]]) -> pd.DataFrame:\n",
    "    scored_df = pd.DataFrame(scored_rows).set_index(\"id\")\n",
    "    merged = df.set_index(\"id\").join(scored_df, how=\"left\")\n",
    "    return merged.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ce730ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt length: 16592 characters across 173 lines.\n",
      "All pilot rows resolved to a model event list.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>respondent</th>\n",
       "      <th>title</th>\n",
       "      <th>form_requested</th>\n",
       "      <th>event_form_used</th>\n",
       "      <th>event_count</th>\n",
       "      <th>event_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>41</td>\n",
       "      <td>Abbot Elementary</td>\n",
       "      <td>Long</td>\n",
       "      <td>short</td>\n",
       "      <td>16</td>\n",
       "      <td>Short form key-moment events (applied to long-form response)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90</td>\n",
       "      <td>62</td>\n",
       "      <td>Abbot Elementary</td>\n",
       "      <td>Long</td>\n",
       "      <td>short</td>\n",
       "      <td>16</td>\n",
       "      <td>Short form key-moment events (applied to long-form response)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>85</td>\n",
       "      <td>Abbot Elementary</td>\n",
       "      <td>Long</td>\n",
       "      <td>short</td>\n",
       "      <td>16</td>\n",
       "      <td>Short form key-moment events (applied to long-form response)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>108</td>\n",
       "      <td>Abbot Elementary</td>\n",
       "      <td>Short</td>\n",
       "      <td>short</td>\n",
       "      <td>16</td>\n",
       "      <td>Short form events</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48</td>\n",
       "      <td>40</td>\n",
       "      <td>Abbot Elementary</td>\n",
       "      <td>Short</td>\n",
       "      <td>short</td>\n",
       "      <td>16</td>\n",
       "      <td>Short form events</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50</td>\n",
       "      <td>69</td>\n",
       "      <td>Abbot Elementary</td>\n",
       "      <td>Short</td>\n",
       "      <td>short</td>\n",
       "      <td>16</td>\n",
       "      <td>Short form events</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id respondent             title form_requested event_form_used  \\\n",
       "0   6         41  Abbot Elementary           Long           short   \n",
       "1  90         62  Abbot Elementary           Long           short   \n",
       "2  12         85  Abbot Elementary           Long           short   \n",
       "3  45        108  Abbot Elementary          Short           short   \n",
       "4  48         40  Abbot Elementary          Short           short   \n",
       "5  50         69  Abbot Elementary          Short           short   \n",
       "\n",
       "   event_count                                                   event_label  \n",
       "0           16  Short form key-moment events (applied to long-form response)  \n",
       "1           16  Short form key-moment events (applied to long-form response)  \n",
       "2           16  Short form key-moment events (applied to long-form response)  \n",
       "3           16                                             Short form events  \n",
       "4           16                                             Short form events  \n",
       "5           16                                             Short form events  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pilot_prompt_text, pilot_missing_keys, pilot_event_metadata = build_batch_prompt(pilot_df, model_events_lookup)\n",
    "\n",
    "print(f\"Prompt length: {len(pilot_prompt_text)} characters across {pilot_prompt_text.count('\\n') + 1} lines.\")\n",
    "if pilot_missing_keys:\n",
    "    print(f\"Missing model event keys: {sorted(pilot_missing_keys)}\")\n",
    "else:\n",
    "    print(\"All pilot rows resolved to a model event list.\")\n",
    "pilot_event_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "04ac3078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert qualitative coder focusing on key-moment recall for media research.\n",
      "Scoring guidelines:\n",
      "- The MODEL EVENTS describe the short-form key moment. Apply them even when the participant viewed the long-form cut.\n",
      "- Compare the participant response to short-form key moment events and assess number of events recalled, accuracy, specificity, and ordering.\n",
      "- Return strictly JSON with the following fields (integers for the scores):\n",
      "    - \"recall_score\": 0-100 (0 = no relevant recall, 100 = richly detailed and accurate).\n",
      "    - \"confidence_score\": 0-100 reflecting your certainty in the judgment.\n",
      "    - \"rationale\": 1-3 sentence explanation referencing the MODEL EVENTS.\n",
      "- If the response states they do not remember, set recall_score to 0 and confidence_score to at least 90.\n",
      "- Ignore long-form events or details that fall outside the MODEL EVENTS (they should not raise the score).\n",
      "- Never invent events beyond the list, and do not include commentary outside the JSON payload.\n"
     ]
    }
   ],
   "source": [
    "print(SYSTEM_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2fbd17a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Abbot Elementary\n",
      "        Respondent form: Long\n",
      "        Event list source: Short form key-moment events (applied to long-form response)\n",
      "        Question code: Q13\n",
      "        Row ID: 6\n",
      "\n",
      "        MODEL EVENTS (chronological):\n",
      "        1. During lunch in the staff room, the teachers eat pizza together while Gregory pointedly avoids taking a slice.\n",
      "2. Gregory’s colleagues notice that he is not eating any pizza and become suspicious that something is wrong.\n",
      "3. Jacob, who previously went out of his way to get the special “Baltimore-style” pizza Gregory claimed to love, places the soggy pizza in front of Gregory.\n",
      "4. Jacob encourages Gregory to take a slice of the “Baltimore-style” pizza while the rest of the staff watch him closely.\n",
      "5. As everyone turns to watch him, Gregory panics and finally admits that he does not like pizza at all.\n",
      "6. Mr. Johnson dramatically drops his mop in shock upon hearing that Gregory does not like pizza.\n",
      "7. Gregory explains that he invented the story about Baltimore-style pizza because he wanted to fit in with his colleagues.\n",
      "8. The group reacts with shock and disbelief, with Melissa, Barbara, and Jacob exclaiming and questioning how anyone could dislike pizza.\n",
      "9. Gregory confesses that he is an extremely picky eater who only enjoys a small number of foods and that he usually hides this because people overreact when they find out.\n",
      "10. Gregory’s coworkers respond theatrically, treating his dislike of pizza as both a betrayal and a bizarre personal quirk.\n",
      "11. The teachers begin to ask Gregory about other foods, such as pie and ribs, testing the extent of his picky eating habits.\n",
      "12. Each time Gregory admits to disliking a common or popular food, his co-workers respond with exaggerated horror and shock.\n",
      "13. Red-faced and defensive, Gregory explains that he lied about liking pizza to avoid exactly this kind of judgment and ridicule.\n",
      "14. When Gregory says he was “born this way,” Jacob jokingly responds, “Don’t you bring Lady Gaga into this,” further teasing him.\n",
      "15. Feeling overwhelmed, embarrassed, and targeted by the teasing, Gregory flees the teachers’ lounge.\n",
      "16. The remaining teachers stay in the lounge, simultaneously aghast and amused by Gregory’s revelation that he does not like pizza.\n",
      "\n",
      "        PARTICIPANT RESPONSE:\n",
      "        So when he said that he liked the pizza from Boston crispy and soggy, he didn't realize that his coworker would go out and buy it and bring it over to him so even though his coworker surprised him with the pizza that he claimed he liked, he still wasn't interested in the pizza. He just said it just to make his coworkers happy\n",
      "\n",
      "        Evaluate this response and return a JSON object with keys id, recall_score, confidence_score, rationale.\n",
      "\n",
      "Title: Abbot Elementary\n",
      "        Respondent form: Long\n",
      "        Event list source: Short form key-moment events (applied to long-form response)\n",
      "        Question code: Q18\n",
      "        Row ID: 90\n",
      "\n",
      "        MODEL EVENTS (chronological):\n",
      "        1. During lunch in the staff room, the teachers eat pizza together while Gregory pointedly avoids taking a slice.\n",
      "2. Gregory’s colleagues notice that he is not eating any pizza and become suspicious that something is wrong.\n",
      "3. Jacob, who previously went out of his way to get the special “Baltimore-style” pizza Gregory claimed to love, places the soggy pizza in front of Gregory.\n",
      "4. Jacob encourages Gregory to take a slice of the “Baltimore-style” pizza while the rest of the staff watch him closely.\n",
      "5. As everyone turns to watch him, Gregory panics and finally admits that he does not like pizza at all.\n",
      "6. Mr. Johnson dramatically drops his mop in shock upon hearing that Gregory does not like pizza.\n",
      "7. Gregory explains that he invented the story about Baltimore-style pizza because he wanted to fit in with his colleagues.\n",
      "8. The group reacts with shock and disbelief, with Melissa, Barbara, and Jacob exclaiming and questioning how anyone could dislike pizza.\n",
      "9. Gregory confesses that he is an extremely picky eater who only enjoys a small number of foods and that he usually hides this because people overreact when they find out.\n",
      "10. Gregory’s coworkers respond theatrically, treating his dislike of pizza as both a betrayal and a bizarre personal quirk.\n",
      "11. The teachers begin to ask Gregory about other foods, such as pie and ribs, testing the extent of his picky eating habits.\n",
      "12. Each time Gregory admits to disliking a common or popular food, his co-workers respond with exaggerated horror and shock.\n",
      "13. Red-faced and defensive, Gregory explains that he lied about liking pizza to avoid exactly this kind of judgment and ridicule.\n",
      "14. When Gregory says he was “born this way,” Jacob jokingly responds, “Don’t you bring Lady Gaga into this,” further teasing him.\n",
      "15. Feeling overwhelmed, embarrassed, and targeted by the teasing, Gregory flees the teachers’ lounge.\n",
      "16. The remaining teachers stay in the lounge, simultaneously aghast and amused by Gregory’s revelation that he does not like pizza.\n",
      "\n",
      "        PARTICIPANT RESPONSE:\n",
      "        The teachers from Abbott elementary are in their break room eating lunch. One of the teachers told them he only liked Baltimore pizza from a made up name in the previous scene, and in this scene the other male teacher drove there and brought it back so he could eat it \"wet\". But really the teacher was lying and hates pizza. And didn't want to tell the other teachers because they would make fun of him. This is the moment he picks up the pizza and then tells them he lied and hates pizza. They are shocked and think he is weird for not liking pizza. He says this is why he didn't tell them in the first place.\n",
      "\n",
      "        Evaluate this response and return a JSON object with keys id, recall_score, confidence_score, rationale.\n",
      "\n",
      "Title: Abbot Elementary\n",
      "        Respondent form: Long\n",
      "        Event list source: Short form key-moment events (applied to long-form response)\n",
      "        Question code: Q13\n",
      "        Row ID: 12\n",
      "\n",
      "        MODEL EVENTS (chronological):\n",
      "        1. During lunch in the staff room, the teachers eat pizza together while Gregory pointedly avoids taking a slice.\n",
      "2. Gregory’s colleagues notice that he is not eating any pizza and become suspicious that something is wrong.\n",
      "3. Jacob, who previously went out of his way to get the special “Baltimore-style” pizza Gregory claimed to love, places the soggy pizza in front of Gregory.\n",
      "4. Jacob encourages Gregory to take a slice of the “Baltimore-style” pizza while the rest of the staff watch him closely.\n",
      "5. As everyone turns to watch him, Gregory panics and finally admits that he does not like pizza at all.\n",
      "6. Mr. Johnson dramatically drops his mop in shock upon hearing that Gregory does not like pizza.\n",
      "7. Gregory explains that he invented the story about Baltimore-style pizza because he wanted to fit in with his colleagues.\n",
      "8. The group reacts with shock and disbelief, with Melissa, Barbara, and Jacob exclaiming and questioning how anyone could dislike pizza.\n",
      "9. Gregory confesses that he is an extremely picky eater who only enjoys a small number of foods and that he usually hides this because people overreact when they find out.\n",
      "10. Gregory’s coworkers respond theatrically, treating his dislike of pizza as both a betrayal and a bizarre personal quirk.\n",
      "11. The teachers begin to ask Gregory about other foods, such as pie and ribs, testing the extent of his picky eating habits.\n",
      "12. Each time Gregory admits to disliking a common or popular food, his co-workers respond with exaggerated horror and shock.\n",
      "13. Red-faced and defensive, Gregory explains that he lied about liking pizza to avoid exactly this kind of judgment and ridicule.\n",
      "14. When Gregory says he was “born this way,” Jacob jokingly responds, “Don’t you bring Lady Gaga into this,” further teasing him.\n",
      "15. Feeling overwhelmed, embarrassed, and targeted by the teasing, Gregory flees the teachers’ lounge.\n",
      "16. The remaining teachers stay in the lounge, simultaneously aghast and amused by Gregory’s revelation that he does not like pizza.\n",
      "\n",
      "        PARTICIPANT RESPONSE:\n",
      "        This is a scene where the one guy drove to Boston maybe to get a wet pizza that the other character said was his favorite pizza. However the character lied and he doesn’t like pizza at all. This scene is from Abbott elementary and it was all the teachers in the break room. In addition to this scene there was a step contest going on.\n",
      "\n",
      "        Evaluate this response and return a JSON object with keys id, recall_score, confidence_score, rationale.\n",
      "\n",
      "Title: Abbot Elementary\n",
      "        Respondent form: Short\n",
      "        Event list source: Short form events\n",
      "        Question code: Q13\n",
      "        Row ID: 45\n",
      "\n",
      "        MODEL EVENTS (chronological):\n",
      "        1. During lunch in the staff room, the teachers eat pizza together while Gregory pointedly avoids taking a slice.\n",
      "2. Gregory’s colleagues notice that he is not eating any pizza and become suspicious that something is wrong.\n",
      "3. Jacob, who previously went out of his way to get the special “Baltimore-style” pizza Gregory claimed to love, places the soggy pizza in front of Gregory.\n",
      "4. Jacob encourages Gregory to take a slice of the “Baltimore-style” pizza while the rest of the staff watch him closely.\n",
      "5. As everyone turns to watch him, Gregory panics and finally admits that he does not like pizza at all.\n",
      "6. Mr. Johnson dramatically drops his mop in shock upon hearing that Gregory does not like pizza.\n",
      "7. Gregory explains that he invented the story about Baltimore-style pizza because he wanted to fit in with his colleagues.\n",
      "8. The group reacts with shock and disbelief, with Melissa, Barbara, and Jacob exclaiming and questioning how anyone could dislike pizza.\n",
      "9. Gregory confesses that he is an extremely picky eater who only enjoys a small number of foods and that he usually hides this because people overreact when they find out.\n",
      "10. Gregory’s coworkers respond theatrically, treating his dislike of pizza as both a betrayal and a bizarre personal quirk.\n",
      "11. The teachers begin to ask Gregory about other foods, such as pie and ribs, testing the extent of his picky eating habits.\n",
      "12. Each time Gregory admits to disliking a common or popular food, his co-workers respond with exaggerated horror and shock.\n",
      "13. Red-faced and defensive, Gregory explains that he lied about liking pizza to avoid exactly this kind of judgment and ridicule.\n",
      "14. When Gregory says he was “born this way,” Jacob jokingly responds, “Don’t you bring Lady Gaga into this,” further teasing him.\n",
      "15. Feeling overwhelmed, embarrassed, and targeted by the teasing, Gregory flees the teachers’ lounge.\n",
      "16. The remaining teachers stay in the lounge, simultaneously aghast and amused by Gregory’s revelation that he does not like pizza.\n",
      "\n",
      "        PARTICIPANT RESPONSE:\n",
      "        The coworkers were trying to get him to eat pizza, even offering some from 2 different places, one he once claimed he liked but discovered that he lied about liking it and is actually a very picky eater. Then he said that's why he does not like to tell people about his eating habits because they often have harsh reactions.\n",
      "\n",
      "        Evaluate this response and return a JSON object with keys id, recall_score, confidence_score, rationale.\n",
      "\n",
      "Title: Abbot Elementary\n",
      "        Respondent form: Short\n",
      "        Event list source: Short form events\n",
      "        Question code: Q13\n",
      "        Row ID: 48\n",
      "\n",
      "        MODEL EVENTS (chronological):\n",
      "        1. During lunch in the staff room, the teachers eat pizza together while Gregory pointedly avoids taking a slice.\n",
      "2. Gregory’s colleagues notice that he is not eating any pizza and become suspicious that something is wrong.\n",
      "3. Jacob, who previously went out of his way to get the special “Baltimore-style” pizza Gregory claimed to love, places the soggy pizza in front of Gregory.\n",
      "4. Jacob encourages Gregory to take a slice of the “Baltimore-style” pizza while the rest of the staff watch him closely.\n",
      "5. As everyone turns to watch him, Gregory panics and finally admits that he does not like pizza at all.\n",
      "6. Mr. Johnson dramatically drops his mop in shock upon hearing that Gregory does not like pizza.\n",
      "7. Gregory explains that he invented the story about Baltimore-style pizza because he wanted to fit in with his colleagues.\n",
      "8. The group reacts with shock and disbelief, with Melissa, Barbara, and Jacob exclaiming and questioning how anyone could dislike pizza.\n",
      "9. Gregory confesses that he is an extremely picky eater who only enjoys a small number of foods and that he usually hides this because people overreact when they find out.\n",
      "10. Gregory’s coworkers respond theatrically, treating his dislike of pizza as both a betrayal and a bizarre personal quirk.\n",
      "11. The teachers begin to ask Gregory about other foods, such as pie and ribs, testing the extent of his picky eating habits.\n",
      "12. Each time Gregory admits to disliking a common or popular food, his co-workers respond with exaggerated horror and shock.\n",
      "13. Red-faced and defensive, Gregory explains that he lied about liking pizza to avoid exactly this kind of judgment and ridicule.\n",
      "14. When Gregory says he was “born this way,” Jacob jokingly responds, “Don’t you bring Lady Gaga into this,” further teasing him.\n",
      "15. Feeling overwhelmed, embarrassed, and targeted by the teasing, Gregory flees the teachers’ lounge.\n",
      "16. The remaining teachers stay in the lounge, simultaneously aghast and amused by Gregory’s revelation that he does not like pizza.\n",
      "\n",
      "        PARTICIPANT RESPONSE:\n",
      "        It was set in a lunchroom at an office. Some people ordered pizza - everyone thought the person on the right loved pizza when in reality he hated pizza. But just told everyone he did to basically fit in and not get questions as to why in the world wouldn't he live pizza. The other people in the lunchroom were asking questions.\n",
      "\n",
      "        Evaluate this response and return a JSON object with keys id, recall_score, confidence_score, rationale.\n",
      "\n",
      "Title: Abbot Elementary\n",
      "        Respondent form: Short\n",
      "        Event list source: Short form events\n",
      "        Question code: Q13\n",
      "        Row ID: 50\n",
      "\n",
      "        MODEL EVENTS (chronological):\n",
      "        1. During lunch in the staff room, the teachers eat pizza together while Gregory pointedly avoids taking a slice.\n",
      "2. Gregory’s colleagues notice that he is not eating any pizza and become suspicious that something is wrong.\n",
      "3. Jacob, who previously went out of his way to get the special “Baltimore-style” pizza Gregory claimed to love, places the soggy pizza in front of Gregory.\n",
      "4. Jacob encourages Gregory to take a slice of the “Baltimore-style” pizza while the rest of the staff watch him closely.\n",
      "5. As everyone turns to watch him, Gregory panics and finally admits that he does not like pizza at all.\n",
      "6. Mr. Johnson dramatically drops his mop in shock upon hearing that Gregory does not like pizza.\n",
      "7. Gregory explains that he invented the story about Baltimore-style pizza because he wanted to fit in with his colleagues.\n",
      "8. The group reacts with shock and disbelief, with Melissa, Barbara, and Jacob exclaiming and questioning how anyone could dislike pizza.\n",
      "9. Gregory confesses that he is an extremely picky eater who only enjoys a small number of foods and that he usually hides this because people overreact when they find out.\n",
      "10. Gregory’s coworkers respond theatrically, treating his dislike of pizza as both a betrayal and a bizarre personal quirk.\n",
      "11. The teachers begin to ask Gregory about other foods, such as pie and ribs, testing the extent of his picky eating habits.\n",
      "12. Each time Gregory admits to disliking a common or popular food, his co-workers respond with exaggerated horror and shock.\n",
      "13. Red-faced and defensive, Gregory explains that he lied about liking pizza to avoid exactly this kind of judgment and ridicule.\n",
      "14. When Gregory says he was “born this way,” Jacob jokingly responds, “Don’t you bring Lady Gaga into this,” further teasing him.\n",
      "15. Feeling overwhelmed, embarrassed, and targeted by the teasing, Gregory flees the teachers’ lounge.\n",
      "16. The remaining teachers stay in the lounge, simultaneously aghast and amused by Gregory’s revelation that he does not like pizza.\n",
      "\n",
      "        PARTICIPANT RESPONSE:\n",
      "        In this scene of Abbott Elementary the subject that was being talked about was favorite foods. The Principal Gregory and another co worker were talking about food or favorite food in the school cafeteria. Gregory was asked what was his favorite food. As Gregory was picking up a slice of the pizza was asking about liking pizza and he said he did not like pizza\n",
      "\n",
      "        Evaluate this response and return a JSON object with keys id, recall_score, confidence_score, rationale.\n"
     ]
    }
   ],
   "source": [
    "print(pilot_prompt_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4396bbc",
   "metadata": {},
   "source": [
    "## LLM Scoring Harness (Run After Approval)\n",
    "Execute the following helper only after the prompt and pilot sample are approved (Stages 3.3-3.6)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "48aae6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"gpt-4.1\"\n",
    "BATCH_SIZE = 3\n",
    "\n",
    "\n",
    "def score_with_llm(df: pd.DataFrame, events_lookup: Dict[Tuple[str, str], List[str]], *, client = openai_client, model: str = MODEL_NAME, batch_size: int = BATCH_SIZE) -> Tuple[pd.DataFrame, List[Tuple[str, str]], List[Dict[str, object]]]:\n",
    "    if df.empty:\n",
    "        raise ValueError(\"No rows supplied for scoring.\")\n",
    "    if client is None:\n",
    "        raise RuntimeError(\"OpenAI client is not initialised. Configure OPENAI_API_KEY before scoring.\")\n",
    "    all_results: List[Dict[str, object]] = []\n",
    "    missing_all: set[Tuple[str, str]] = set()\n",
    "    prompt_artifacts: List[Dict[str, object]] = []\n",
    "    for batch_index, start in enumerate(range(0, len(df), batch_size), start=1):\n",
    "        batch_df = df.iloc[start : start + batch_size]\n",
    "        prompt_text, missing_keys, metadata_df = build_batch_prompt(batch_df, events_lookup)\n",
    "        prompt_artifacts.append({\n",
    "            \"batch_index\": batch_index,\n",
    "            \"prompt\": prompt_text,\n",
    "            \"metadata\": metadata_df,\n",
    "        })\n",
    "        if missing_keys:\n",
    "            missing_all.update(missing_keys)\n",
    "        raw_response = call_llm_batch(prompt_text, client_obj=client, model=model)\n",
    "        batch_results = parse_llm_json(raw_response)\n",
    "        for entry in batch_results:\n",
    "            entry[\"id\"] = int(entry[\"id\"])\n",
    "            entry[\"recall_score\"] = int(entry[\"recall_score\"])\n",
    "            entry[\"confidence_score\"] = int(entry[\"confidence_score\"])\n",
    "        all_results.extend(batch_results)\n",
    "        print(f\"✓ Batch {batch_index} completed ({len(batch_results)} rows).\")\n",
    "    scored_df = enrich_dataframe_with_scores(df, all_results)\n",
    "    return scored_df, sorted(missing_all), prompt_artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "922dde74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Batch 1 completed (3 rows).\n",
      "✓ Batch 2 completed (3 rows).\n",
      "\n",
      "✓ Pilot scoring saved to recall_openended\\key moment\\pilot_outputs\\recall_coded_responses_key_moment_pilot.csv\n",
      "✓ All rows scored successfully with no missing event keys.\n",
      "\n",
      "Pilot results preview:\n",
      "✓ Batch 2 completed (3 rows).\n",
      "\n",
      "✓ Pilot scoring saved to recall_openended\\key moment\\pilot_outputs\\recall_coded_responses_key_moment_pilot.csv\n",
      "✓ All rows scored successfully with no missing event keys.\n",
      "\n",
      "Pilot results preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>respondent</th>\n",
       "      <th>form</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>confidence_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>41</td>\n",
       "      <td>Long</td>\n",
       "      <td>35</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90</td>\n",
       "      <td>62</td>\n",
       "      <td>Long</td>\n",
       "      <td>70</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>85</td>\n",
       "      <td>Long</td>\n",
       "      <td>40</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>108</td>\n",
       "      <td>Short</td>\n",
       "      <td>70</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48</td>\n",
       "      <td>40</td>\n",
       "      <td>Short</td>\n",
       "      <td>55</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50</td>\n",
       "      <td>69</td>\n",
       "      <td>Short</td>\n",
       "      <td>35</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id respondent   form  recall_score  confidence_score\n",
       "0   6         41   Long            35                95\n",
       "1  90         62   Long            70                98\n",
       "2  12         85   Long            40                95\n",
       "3  45        108  Short            70                95\n",
       "4  48         40  Short            55                90\n",
       "5  50         69  Short            35                90"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Execute pilot scoring (Step 3.3)\n",
    "scored_pilot_df, missing_event_keys, prompt_artifacts = score_with_llm(pilot_df, model_events_lookup)\n",
    "scored_pilot_df.to_csv(PILOT_OUTPUT_PATH, index=False)\n",
    "print(f\"\\n✓ Pilot scoring saved to {PILOT_OUTPUT_PATH.relative_to(PROJECT_ROOT)}\")\n",
    "if missing_event_keys:\n",
    "    print(f\"⚠ Missing model event keys encountered: {missing_event_keys}\")\n",
    "else:\n",
    "    print(\"✓ All rows scored successfully with no missing event keys.\")\n",
    "    \n",
    "print(f\"\\nPilot results preview:\")\n",
    "scored_pilot_df[[\"id\", \"respondent\", \"form\", \"recall_score\", \"confidence_score\"]].head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
